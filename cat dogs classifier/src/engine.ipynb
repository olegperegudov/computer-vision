{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0bd47a18303be29f6974e8153b6e52f9a90ee51d979b528b256bf5f0592078974",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "bd47a18303be29f6974e8153b6e52f9a90ee51d979b528b256bf5f0592078974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torchvision import datasets\n",
    "# import torchvision.models as models\n",
    "\n",
    "# import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMS HERE\n",
    "\n",
    "# params\n",
    "lr = 3e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 3e-3\n",
    "\n",
    "# transforms\n",
    "presize = 256\n",
    "crop = 256\n",
    "\n",
    "# batch size\n",
    "batch_size = 32\n",
    "\n",
    "# n_epochs\n",
    "frozen = 1\n",
    "unfrozen = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transform = A.Compose([\n",
    "        A.SmallestMaxSize(presize),\n",
    "        A.RandomCrop(crop, crop),\n",
    "        A.Normalize(),\n",
    "        A.HorizontalFlip(),\n",
    "        A.Rotate(limit=30),\n",
    "        A.Cutout(),\n",
    "        albumentations.pytorch.ToTensorV2()])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "        A.SmallestMaxSize(presize),\n",
    "        A.CenterCrop(crop, crop),\n",
    "        A.Normalize(),\n",
    "        albumentations.pytorch.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.df.shape[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.df.fname[index]).convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        label = torch.tensor(self.df.label[index]).long()  \n",
    "\n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image=image)\n",
    "            image = augmentations['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-2add2b7f0ac0>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-2add2b7f0ac0>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    ROOT = Path.cwd().parent\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# setting paths\n",
    "    ROOT = Path.cwd().parent\n",
    "    # image data files\n",
    "    DATA = os.path.join(ROOT, 'data')\n",
    "    # dataframes for training\n",
    "    INPUT = os.path.join(ROOT, 'input')\n",
    "    # our input df\n",
    "    DF_PATH = os.path.join(INPUT, 'train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DF_PATH)\n",
    "\n",
    "train_df = df[df.kfold!=0].reset_index(drop=True)\n",
    "valid_df = df[df.kfold==0].reset_index(drop=True)\n",
    "\n",
    "# create dataset\n",
    "train_dataset = dataset(train_df, train_transform)\n",
    "test_dataset = dataset(test_df, test_transform)\n",
    "# create loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True, \n",
    "                                            num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True, \n",
    "                                            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displayig the data (looks this way because of normalization)\n",
    "batch_tensor = next(iter(train_loader))[0][:10,...]\n",
    "grid_img = torchvision.utils.make_grid(batch_tensor, nrow=5)\n",
    "# grid_img.shape\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.imshow(grid_img.permute(1, 2, 0)); # uncomment to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a check if all is good with the shapes of the loaders\n",
    "print(f'dataloader test: {next(iter(train_loader))[0].shape}, {next(iter(test_loader))[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "# learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main train function\n",
    "def train_model(n_epochs=1,\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer, \n",
    "                lr_scheduler=lr_scheduler):\n",
    "\n",
    "    print(f'================')\n",
    "    print(f'started training...')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_time = round(time.time() - t0)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        test_loss, test_auc = test_model(model, test_loader)\n",
    "        \n",
    "        print(f'epoch: [{epoch+1}/{n_epochs}], train loss: {epoch_loss:.3f}, valid loss: {test_loss}, roc auc: {test_auc}, time: {epoch_time//60:.0f}m {epoch_time%60:.0f}s')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for validation or testing\n",
    "def test_model(model=model, test_loader=test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    roc_auc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch, (images, labels) in enumerate(test_loader):\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss\n",
    "            roc_auc += roc_auc_score_multiclass(labels, preds)\n",
    "\n",
    "    avg_epoch_loss = round(float(epoch_loss / len(test_loader)), 3)\n",
    "    avg_roc_auc = round(float(roc_auc / len(test_loader)), 3)\n",
    "\n",
    "    return avg_epoch_loss, avg_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze all the params for training\n",
    "def unfreeze(model=model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model"
   ]
  }
 ]
}